{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"XorbMSz1hpvN","executionInfo":{"status":"ok","timestamp":1725804733401,"user_tz":-540,"elapsed":2720,"user":{"displayName":"한준재","userId":"18400352313517335546"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7551633e-b9be-4cb7-8da5-deff67937b13"},"id":"XorbMSz1hpvN","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"id":"7eff3505-5a73-47dd-86f1-d3a6f6fe3216","metadata":{"id":"7eff3505-5a73-47dd-86f1-d3a6f6fe3216","outputId":"67dd019d-65f8-41ac-f115-17fbbf423477","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725804733401,"user_tz":-540,"elapsed":12,"user":{"displayName":"한준재","userId":"18400352313517335546"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["스팸 : 정상 비율 : 0.873669955503966 : 0.12633004449603405\n"]}],"source":["import pandas\n","\n","data = pandas.read_csv(\"/content/drive/Othercomputers/내 노트북/File/spamVenv/files/spam.csv\", encoding=\"latin1\")\n","data = data[['v1', 'v2']].rename(columns={\"v1\":\"isSpam\", \"v2\":\"content\"}).drop_duplicates() #제목, 스팸여부 & 중복제거(결측치)\n","data[\"isSpam\"] = data['isSpam'].replace([\"ham\", \"spam\"], [0, 1]) #범주형 -> 수치형\n","data[\"isSpam\"].value_counts() #스팸 비율\n","print(f'스팸 : 정상 비율 : {data[\"isSpam\"].value_counts()[0]/data[\"isSpam\"].size} : {data[\"isSpam\"].value_counts()[1]/data[\"isSpam\"].size}')"]},{"cell_type":"code","execution_count":null,"id":"cd9f011d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cd9f011d","executionInfo":{"status":"ok","timestamp":1725804733401,"user_tz":-540,"elapsed":10,"user":{"displayName":"한준재","userId":"18400352313517335546"}},"outputId":"4896d298-4b92-4ad1-de37-2687d768be62"},"outputs":[{"output_type":"stream","name":"stdout","text":["훈련데이터 정상 메일 = 87%\n","훈련데이터 스팸 메일 = 13%\n","총 훈련데이터 수 : 4652개 중 3721개, 80%\n","테스트데이터 정상 메일 = 87%\n","테스트데이터 스팸 메일 = 13%\n","총 테스트데이터 수 : 4652개 중 931개, 20%\n","뽑은 데이터 비율 = 90%, 총 5169개 중 4652개 선별.\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","dataRatio  = 0.9\n","Xdata, _, Ydata, _ = train_test_split(data[\"content\"], data[\"isSpam\"], test_size=1 - dataRatio, random_state=123, stratify=data[\"isSpam\"])\n","\n","Xtrain, Xtest, Ytrain, Ytest = train_test_split(Xdata, Ydata, test_size=0.2, random_state=123, stratify=Ydata) #훈련데이터, 테스트데이터 나누기 (비율 8:2, 시드값 123?)\n","print(f'훈련데이터 정상 메일 = {round(Ytrain.value_counts()[0]/len(Ytrain) * 100)}%')\n","print(f'훈련데이터 스팸 메일 = {round(Ytrain.value_counts()[1]/len(Ytrain) * 100)}%')\n","print(f'총 훈련데이터 수 : {Ydata.size}개 중 {Ytrain.size}개, {round(Ytrain.size/Ydata.size*100)}%')\n","print(f'테스트데이터 정상 메일 = {round(Ytest.value_counts()[0]/len(Ytest) * 100)}%')\n","print(f'테스트데이터 스팸 메일 = {round(Ytest.value_counts()[1]/len(Ytest) * 100)}%')\n","print(f'총 테스트데이터 수 : {Ydata.size}개 중 {Ytest.size}개, {round(Ytest.size/Ydata.size*100)}%')\n","print(f'뽑은 데이터 비율 = {round(Ydata.size/data[\"isSpam\"].size * 100)}%, 총 {data[\"isSpam\"].size}개 중 {Ydata.size}개 선별.')\n","\n","\n"]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from numpy import mean\n","\n","tokenizer = Tokenizer() #토큰화 진행\n","tokenizer.fit_on_texts(Xdata) #각 단어를 숫자와 매핑시키는 집합 생성\n","encodedXtrain = tokenizer.texts_to_sequences(Xtrain) #각 문장의 단어들을 위 집합을 기반으로 [abc, cba] -> [3,39] 와 같이 변경 : encoding된 느낌\n","\n","meanLen = round(mean([len(i) for i in Xdata])) #문장의 길이를 통일하기 위해 문장의 길이 평균값 -> 값 : 79정도\n","\n","finalXtrain = pad_sequences(encodedXtrain, maxlen=meanLen) #입력 데이터 최종본 : 위에서 숫자로 이루어진 문장을 모두 같은 길이의 문장으로 만들어줌(0으로 채워넣는 pad sequence)\n","Xtrain.iloc[0], encodedXtrain[0], finalXtrain[0], print(f'문장의 길이 평균값 : {meanLen}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X7nkn4uvkFyJ","executionInfo":{"status":"ok","timestamp":1725804733401,"user_tz":-540,"elapsed":8,"user":{"displayName":"한준재","userId":"18400352313517335546"}},"outputId":"d04492c4-7ad6-433f-a9c6-0dd845406c43"},"id":"X7nkn4uvkFyJ","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["문장의 길이 평균값 : 79\n"]},{"output_type":"execute_result","data":{"text/plain":["('Aiyar dun disturb u liao... Thk u have lots 2 do aft ur cupboard come...',\n"," [1752, 232, 1392, 6, 368, 235, 6, 16, 728, 20, 29, 573, 39, 7033, 59],\n"," array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0, 1752,  232,\n","        1392,    6,  368,  235,    6,   16,  728,   20,   29,  573,   39,\n","        7033,   59], dtype=int32),\n"," None)"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Dense, Flatten, SimpleRNN\n","\n","model = Sequential()\n","model.add(Embedding(len(tokenizer.word_index)+1, 32, input_length=meanLen)) #Embedding(단어 집합 길이 + 1, 출력 차원, 입력 최대 길이) -> 입력층\n","# model.add(SimpleRNN(32))\n","model.add(Flatten()) #다차원을 1차원으로 바꾸어 Dense에 들어갈 수 있도록 변환\n","model.add(Dense(5, activation='relu'))\n","model.add(Dense(1, activation=\"sigmoid\")) #sigmoid함수를 활성화 함수로 하는 Dense, 출력 1개 -> 출력층\n","model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"],"metadata":{"id":"YcdWo7a1lopt"},"id":"YcdWo7a1lopt","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","startTime = time.time()\n","model.fit(finalXtrain, Ytrain, epochs=2, batch_size=32) # 전체 데이터를 2번, 32개씩 풀고 채점\n","endTime = time.time()\n","print(f'걸린 시간 : {endTime - startTime}초')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"50O7uc4Do1-q","executionInfo":{"status":"ok","timestamp":1725804735336,"user_tz":-540,"elapsed":1940,"user":{"displayName":"한준재","userId":"18400352313517335546"}},"outputId":"4c6c3d68-dac2-43ed-94ba-ec9e6d3e5402"},"id":"50O7uc4Do1-q","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","117/117 [==============================] - 1s 4ms/step - loss: 0.2848 - accuracy: 0.8737\n","Epoch 2/2\n","117/117 [==============================] - 0s 4ms/step - loss: 0.1389 - accuracy: 0.9643\n","걸린 시간 : 1.6130201816558838초\n"]}]},{"cell_type":"code","source":["#모델을 평가하기 위해 test데이터를 전처리 하는 과정(encoding, pad ...)\n","encodedXtest = tokenizer.texts_to_sequences(Xtest)\n","finalXtest = pad_sequences(encodedXtest, maxlen=meanLen)\n","\n","loss, accuracy = model.evaluate(finalXtest, Ytest, batch_size = 32)\n","print(f'정확도 : {accuracy*100}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i2GdXb1AqsZd","executionInfo":{"status":"ok","timestamp":1725804735337,"user_tz":-540,"elapsed":7,"user":{"displayName":"한준재","userId":"18400352313517335546"}},"outputId":"9c5ac7fb-2d6e-4f18-e26f-8f5c817d42fd"},"id":"i2GdXb1AqsZd","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["30/30 [==============================] - 0s 2ms/step - loss: 0.1212 - accuracy: 0.9774\n","정확도 : 97.74436354637146%\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"colab":{"provenance":[],"gpuType":"V28"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":5}